---
title: "rjmc_usage"
author: "David Hodgson"
output: rmarkdown::github_document
vignette: >
  %\VignetteIndexEntry{PTMC_usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup}
#devtools::install("..") #install if needed
devtools::load_all()

library(rjmc)
library(tidyverse) 
library(coda)
library(parallel)

```

# Reversible Jump Markov Chain Monte Carlo

```{r model definition}

data_here <- readRDS(here::here("vingettes", "preD_pcr.rds") )

# restructure the data for the log-likelihood function
data_t <-   list(
  N = length(data_here$daybleed2),
  knownInfsVec = data_here$known,        
  knownInfsN = sum(data_here$known),
  time_bleed2 = data_here$daybleed2,
  dayinf = data_here$dayinf,
  age = data_here$age_group,
  pre_t = data_here$ptna_B.1.1.7_V1_log,
  boost_t = data_here$ptna_B.1.1.7_V2_log - data_here$ptna_B.1.1.7_V1_log
)


# 220 total
# 114 known
# 106 unknown 

# model is a list of three functions and a vector string
model <- list(

  lowerParSupport_fitted = c(0, 0, -2, 0, 0),
  upperParSupport_fitted = c(6, 1, 2, 10, 10),

  namesOfParameters = c("boost", "wane", "titre_boost", "sigma_b", "sigma_p"),

  samplePriorDistributions = function(datalist) {
     c(
      runif(1, 0, 6),
      runif(1, 0, 1),
      runif(1, -2, 2),
      rexp(1),
      rexp(1)
    )
  },

  evaluateLogPrior = function(params, jump, datalist) {
    lpr <- 0
    lpr <- lpr + dunif( params[1], 0, 6, log = TRUE)
    lpr <- lpr + dunif( params[2], 0, 1, log = TRUE)
    lpr <- lpr + dunif( params[3], -2, 2, log = TRUE)
    lpr <- lpr + dexp( params[4], 1, log = TRUE)
    lpr <- lpr + dexp( params[5], 1, log = TRUE)
    lpr
  },

  initialiseJump = function(datalist) {
    c(0, datalist$dayinf)
  },

  jumpSampling = function(jump, datalist) {

      n_ <- 0
      N <- datalist$N
      for (i in 1:N) {
        if (jump[i + 1] > 0) {
          n_ <- n_ + 1
        }
      }

    find_s_unknown_missed <- function(datalist, jump) {
      s <- sample(datalist$N, 1) 
      while (datalist$known[s] == 1 | jump[s + 1] == -1 ) {
        s <- sample(datalist$N, 1) 
      }
      s
    }
    find_s_unknown_notmissed <- function(datalist, jump) {
      s <- sample(datalist$N, 1) 
      while (datalist$known[s] == 1 | jump[s + 1] != -1 ) {
        s <- sample(datalist$N, 1) 
      }
      s
    }

    # Proposal value for k according to stochastic matrix Q, Qkk = Qk,k-1 = Qk,k+1 = 1/3
    q <- runif(1, 0, 1)
    if (n_ - 114 == 0) {
      q_prob <- c(0, 0.67, 1.0)
    } else if (n_ - 114 == 106) {
      q_prob <- c(0.33, 1.0, 0)
    } else {
       q_prob <- c(0.33, 0.67, 1.0)
    }
    # Substract a value
    if (q < q_prob[1]) {
        s <- find_s_unknown_missed(datalist, jump) # length is n_ - 114
        jump[s + 1] = -1 # length now n_ - 144 - 1
        jump[1] = 0
    # Stay same
    } else if (q < q_prob[2]) {
        if(n_ - 114 != 0) {
          s <- find_s_unknown_missed(datalist, jump) # length is n_ - 114
          jump[s + 1] <- runif(1, 50, 250)
        }
        jump[1] = 1
    # Add an infection same
    } else if (q < q_prob[3]) {
        s <- find_s_unknown_notmissed(datalist, jump) # length is 220 - n_
        jump[s + 1] <- runif(1, 50, 250)
        jump[1] = 2
    }
    jump
  },

  evaluateLogLikelihood = function(params, jump, covariance, datalist) {
    N <-  datalist$N
    timeb2 <- datalist$time_bleed2
    time_inf <- datalist$dayinf

    pre_t <- datalist$pre_t
    boost_t <- datalist$boost_t

    ll <- 0
    # Likelihood of old
    for (i in 1:N) {
      if (jump[i + 1] > 0) {
        mu <- params[1] + pre_t[i] * params[3] - params[2] * (timeb2[i] - jump[i + 1])
        ll <- ll + dnorm(mu, boost_t[i], params[4], log = TRUE)
      } else {
        ll <- ll + dnorm(0, boost_t[i], params[4], log = TRUE)
      }
    }
    ll
  },

  evaluateAcceptanceRatioR = function(jump, proposal_ll, current_ll, datalist) {
    n_ <- 0
    N <- datalist$N
    for (i in 1:N) {
      if (jump[i + 1] > 0) {
         n_ <- n_ + 1
      }
    }
    if (jump[1] == 0) {
      accept <- proposal_ll - current_ll + log(n_ - 114) - log((220 - n_ + 1) )
    } else if (jump[1] == 1) {
      accept <- proposal_ll - current_ll
    } else if (jump[1] == 2) {
      accept <- proposal_ll - current_ll + log((220 - n_) ) - log(n_ - 114 + 1) 
    }
    accept
  }
)




```



```{r settings}


# settings used for the ptmc model 
settings <-  list(
  numberChainRuns = 4,
  numberTempChains = 1,
  iterations = 1000000,
  burninPosterior = 500000,
  thin = 1000,
  consoleUpdates = 1000,
  numberFittedPar = 5,
  onAdaptiveCov = TRUE,
  updatesAdaptiveCov = 200,
  burninAdaptiveCov = 100,
  onAdaptiveTemp = TRUE,
  updatesAdaptiveTemp = 10,
  onDebug = FALSE,
  lowerParBounds = model$lowerParSupport_fitted,
  upperParBounds = model$upperParSupport_fitted,
  covarInitVal = 1, # make very small if struggling to sample to beginning
  covarInitValAdapt = 1e-1, # make very small if struggling to sample to beginning
  covarMaxVal = 1, # decrease if struggling to sample in the middle
  runParallel = FALSE,
  numberCores = 4,
  lengthJumpVec = data_t$N + 1
)

data_t$boost_t

post <- rjmc_sero_func(model = model, data = data_t, settings = settings)
saveRDS(post, here::here("outputs", "play", "long_v.RData"))

summary(post$mcmc)


(post$jump[[2]][, 1] == -1) %>% sum
(post$jump[[1]][, 11] == -1) %>% sum

post_of_missed <- post$jump[[4]][, which(data_here$known == 0) + 1] 

size_missed <- 1:106 %>% map( ~(post_of_missed[, .x] != -1) %>% sum ) %>% unlist
size_missed[which(size_missed > 400)]

lol <- post$jump[[4]][, which(data_here$known == 0) + 1][, which(size_missed > 400)] 

x <- 14
lol[, x][lol[, x] > -1] %>% hist

data_t$dayinf[data_t$known]

data_t$pre_t[which(data_t$known == 0)]
data.frame(
  data = data_t$boost_t[which(data_t$known == 0)],
  model_prop = size_missed
) %>% ggplot() + geom_point(aes(x = data, y = model_prop))


data.frame(data_t$pre_t[which(data_t$known == 0)], data_t$boost_t[which(data_t$known == 0)])


```

### Run the model.

```{r run model,  message=FALSE, results = 'hide'}

mcmc_combine <- post$mcmc %>% combine 

output_plots <- 1:data_t$N %>% map_df(
  function(x) {
    time <- data_t[[2]][x]
    start <- data_t[[4]][x]
    boost <- data_t[[5]][x]

    data.frame(
      id = x,
      data = boost,
      post = (mcmc_combine[, 1] + start * mcmc_combine[, 3] - (time * mcmc_combine[, 2])) %>% as.numeric
    )
  }
)

require(ggdist)
output_plots %>% 
  ggplot() + 
  stat_pointinterval(aes(x  = as.character(id), y = post )) + 
  geom_point(aes(x = as.character(id), y = data), color = "red", size = 2)

boost_titre_dep <- 0:8 %>% map_df(
  function(x) {
    data.frame(
      pret = x,
      post = (mcmc_combine[, 1] + x * mcmc_combine[, 3]) %>% as.numeric
    )
  }
)

boost_titre_dep %>% 
  ggplot() + stat_lineribbon(aes(x = pret, y = post), alpha = 0.5,  fill = "red") + 
    geom_point(data = data_here, aes(x = ptna_B.1.1.7_V1_log, y = ptna_B.1.1.7_V2_log - ptna_B.1.1.7_V1_log))


```

## Plot the data 
`ptmc_func` returns a list of length two. The first entry is `post$mcmc` a mcmc or mcmc.list object (from the coda package). I can plot these and calculate convergence diagnostics using coda functions:

```{r plot outcomes}
library(posterior)
library(coda)
library(bayesplot)
summary(post$mcmc)

post$mcmc %>% mcmc_trace


# Plot the Gelman-Rubin diagnostic for the parameters
gelman.plot(post$mcmc)
gelman.diag(post$mcmc)

```

The second entry is `post$lpost` and is long table dataframe of the log-posterior values. These values can be easily plotted using ggplot2:
```{r}
# Plot of the logposterior for the three chains
lpost_conv <- post$lpost %>% filter(sample_no>100)
logpostplot <- ggplot(lpost_conv, aes(x = sample_no, y = lpost)) + 
  geom_line(aes(color = chain_no), size = 0.5, alpha=0.8) +
  theme_minimal()
logpostplot

```